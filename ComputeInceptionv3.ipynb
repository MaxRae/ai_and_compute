{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI & Compute, Inception-v3\n",
    "\n",
    "Inception-v3 is identical to Inception-v2 from [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/pdf/1512.00567.pdf), only that it's the version \"in which the fully connected layer of the auxiliary classifier is also batch-normalized, not just the convolutions.\"\n",
    "\n",
    "##### About my estimation:\n",
    "\n",
    "- table 1 in the paper summarizes the network architecture\n",
    "- I wrote functions for all types of layers and modules and then use them to estimate the compute of a forward pass\n",
    "- I then use the formula from OpenAI's \"AI and Compute\" to estimate total compute [3]\n",
    "\n",
    "#### Open questions\n",
    "- currently I ignore the batch-normalization, does this increase the compute costs meaningfully?\n",
    "\n",
    "#### Notes\n",
    "- I looked up Towards Data Science intros to CNNs [1,2] to understand the calculations that go into a convolutional layer\n",
    "\n",
    "[1] https://towardsdatascience.com/an-introduction-to-convolutional-neural-networks-eb0b60b58fd7\n",
    "\n",
    "[2] https://towardsdatascience.com/convolution-neural-network-for-image-processing-using-keras-dc3429056306\n",
    "\n",
    "[3] https://openai.com/blog/ai-and-compute/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_compute(kernel_size, stride, input_size, total_kernels):\n",
    "    #how often does the kernel fit on the input?\n",
    "    total_convolutions = kernel_fits(kernel_size, stride, input_size)\n",
    "    \n",
    "    #computations per convolution\n",
    "    #third dimension of the kernel is the depth of the input size\n",
    "    total_multiplications = kernel_size[0] * kernel_size[1] * input_size[2]\n",
    "    total_additions = total_multiplications # adding all the products together\n",
    "    comp_per_conv = total_multiplications + total_additions\n",
    "    \n",
    "    return comp_per_conv * total_convolutions * total_kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_compute(kernel_size, stride, input_size):\n",
    "    total_pools = kernel_fits(kernel_size, stride, input_size)\n",
    "    \n",
    "    #finding max is O(n)\n",
    "    total_comparisons = kernel_size[0] * kernel_size[1] * input_size[2]\n",
    "    return total_comparisons * total_pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incept_compute_1(stride=1, input_size=[35,35,288]):\n",
    "    # figure 5\n",
    "    strand_one = \\\n",
    "    conv_compute(kernel_size=[1,1],\n",
    "                 stride=1,\n",
    "                 input_size=input_size, \n",
    "                 total_kernels=input_size[2]) \\\n",
    "    + conv_compute([3,3],1,input_size, input_size[2]) \\\n",
    "    + conv_compute([3,3],1,input_size, input_size[2]) \\\n",
    "\n",
    "    strand_two = \\\n",
    "    conv_compute([1,1],1,input_size, input_size[2]) \\\n",
    "    + conv_compute([3,3],1,input_size, input_size[2]) \\\n",
    "    \n",
    "    strand_three = \\\n",
    "    pool_compute([1,1],1,input_size) \\\n",
    "    + conv_compute([1,1],1,input_size, input_size[2]) \\\n",
    "    \n",
    "    strand_four = \\\n",
    "    conv_compute([1,1],1,input_size, input_size[2]) \\\n",
    "    \n",
    "    return strand_one + strand_two + strand_three + strand_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incept_compute_2(stride=1, input_size=[35,35,288]):\n",
    "    # figure 6\n",
    "    strand_one = \\\n",
    "    conv_compute(kernel_size=[1,1],\n",
    "                 stride=1,\n",
    "                 input_size=input_size, \n",
    "                 total_kernels=input_size[2]) \\\n",
    "    + conv_compute([1,7],1,input_size, input_size[2]) \\\n",
    "    + conv_compute([7,1],1,input_size, input_size[2]) \\\n",
    "    + conv_compute([1,7],1,input_size, input_size[2]) \\\n",
    "    + conv_compute([7,1],1,input_size, input_size[2]) \\\n",
    "\n",
    "    strand_two = \\\n",
    "    conv_compute([1,1],1,input_size, input_size[2]) \\\n",
    "    + conv_compute([1,7],1,input_size, input_size[2]) \\\n",
    "    + conv_compute([7,1],1,input_size, input_size[2]) \\\n",
    "    \n",
    "    strand_three = \\\n",
    "    pool_compute([1,1],1,input_size) \\\n",
    "    + conv_compute([1,1],1,input_size, input_size[2]) \\\n",
    "    \n",
    "    strand_four = \\\n",
    "    conv_compute([1,1],1,input_size, input_size[2]) \\\n",
    "    \n",
    "    return strand_one + strand_two + strand_three + strand_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incept_compute_3(stride=1, input_size=[35,35,288]):\n",
    "    # figure 7\n",
    "    strand_one = \\\n",
    "    conv_compute(kernel_size=[1,1],\n",
    "                 stride=1,\n",
    "                 input_size=input_size, \n",
    "                 total_kernels=input_size[2]) \\\n",
    "    + conv_compute([3,3],1,input_size, input_size[2]) \\\n",
    "    + conv_compute([3,1],1,input_size, input_size[2]) \\\n",
    "    + conv_compute([1,3],1,input_size, input_size[2])\n",
    "\n",
    "    strand_two = \\\n",
    "    conv_compute([1,1],1,input_size, input_size[2]) \\\n",
    "    + conv_compute([1,3],1,input_size, input_size[2]) \\\n",
    "    + conv_compute([3,1],1,input_size, input_size[2])\n",
    "    \n",
    "    strand_three = \\\n",
    "    pool_compute([1,1],1,input_size) \\\n",
    "    + conv_compute([1,1],1,input_size, input_size[2]) \\\n",
    "    \n",
    "    strand_four = \\\n",
    "    conv_compute([1,1],1,input_size, input_size[2]) \\\n",
    "    \n",
    "    return strand_one + strand_two + strand_three + strand_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_compute(input_size, output_size):\n",
    "    # mapping from 2048 to 1000\n",
    "    # so you have 1000 * 2048 connections/multiplications + that many additions of the bias\n",
    "    return 2 * input_size[2] * output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_compute(input_size):\n",
    "    # exponentiating each input and deviding by the sum\n",
    "    return input_size[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_fits(kernel_size, stride, input_size):\n",
    "    #how often will the kernel be applied to the input?\n",
    "    vertical_fit = input_size[0] / kernel_size[0]\n",
    "    horizontal_fit = input_size[1] / kernel_size[1]\n",
    "    layers = input_size[2]\n",
    "    return layers * vertical_fit * horizontal_fit / stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_size(kernel_size, stride, input_size):\n",
    "    vertical_fit = input_size[0] / kernel_size[0] / stride\n",
    "    horizontal_fit = input_size[1] / kernel_size[1] / stride\n",
    "    return [vertical_fit, horizontal_fit, input_size[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate compute of forward pass\n",
    "The layers are taken from table 1 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_pass_compute = \\\n",
    "conv_compute(kernel_size=[3,3],\n",
    "                stride=2,\n",
    "                input_size=[299,299,3], \n",
    "                total_kernels=32) \\\n",
    "+ conv_compute([3,3],2,[149,149,32], 32) \\\n",
    "+ conv_compute([3,3],2,[147,147,32], 64) \\\n",
    "+ pool_compute([3,3],2,[147,147,64]) \\\n",
    "+ conv_compute([3,3],2,[73,73,64], 80) \\\n",
    "+ conv_compute([3,3],2,[71,71,80], 192) \\\n",
    "+ conv_compute([3,3],2,[35,35,192], 288) \\\n",
    "+ incept_compute_1([35,35,288]) \\\n",
    "+ incept_compute_2([17,17,768]) \\\n",
    "+ incept_compute_3([8,8,1280]) \\\n",
    "+ pool_compute([3,3],2,[8,8,2048]) \\\n",
    "+ linear_compute([1,1,2048], 1000) \\\n",
    "+ softmax_compute([1,1,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate total compute\n",
    "I use the formula from OpenAI's article [\"AI and Compute\"](https://openai.com/blog/ai-and-compute/)\n",
    "\n",
    ">(add-multiplies per forward pass) * \n",
    "(2 FLOPs/add-multiply) * \n",
    "(3 for forward and backward pass) * \n",
    "(number of examples in dataset) *\n",
    "(number of epochs)\n",
    "\n",
    "Relevant data from the paper:\n",
    "> #### 8. Training Methodology\n",
    "> We have trained our networks with stochastic gradient utilizing the TensorFlow [1] distributed machine learning system using 50 replicas running each on a NVidia Kepler GPU with batch size 32 for 100 epochs\n",
    "\n",
    "Finally, there are 1.2 million images in ILSVRC 2012's training data. [source](https://image-net.org/challenges/LSVRC/2012/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1125875164832e+21"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass_compute * 2 * 3 * 1.2E6 * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
